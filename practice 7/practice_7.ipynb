{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHEq6dvlJlkA",
        "outputId": "a5f3814d-ab59-4385-d4a9-b6f3c373cc1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction.cu\n",
        "#include <iostream>                 // Я подключаю ввод-вывод\n",
        "#include <cuda_runtime.h>           // Я подключаю CUDA\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define CHECK(call) do {                                                \\\n",
        "    cudaError_t err = (call);                                           \\\n",
        "    if (err != cudaSuccess) {                                           \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(err)               \\\n",
        "             << \" at line \" << __LINE__ << endl;                        \\\n",
        "        return 1;                                                       \\\n",
        "    }                                                                   \\\n",
        "} while(0)\n",
        "\n",
        "__global__ void reduceSum(const float* input, float* blockSums, int n) {\n",
        "    __shared__ float sdata[256];              // Я использую shared memory для блока\n",
        "\n",
        "    int tid = threadIdx.x;                    // Я беру индекс потока в блоке\n",
        "    int i = blockIdx.x * blockDim.x + tid;    // Я считаю глобальный индекс\n",
        "\n",
        "    sdata[tid] = (i < n) ? input[i] : 0.0f;   // Я загружаю элемент или 0\n",
        "    __syncthreads();                          // Я синхронизирую потоки\n",
        "\n",
        "    for (int s = blockDim.x / 2; s > 0; s >>= 1) { // Я делаю редукцию внутри блока\n",
        "        if (tid < s) {\n",
        "            sdata[tid] += sdata[tid + s];     // Я суммирую пары\n",
        "        }\n",
        "        __syncthreads();                      // Я синхронизирую после шага\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {                           // Первый поток блока\n",
        "        blockSums[blockIdx.x] = sdata[0];     // Я записываю сумму блока\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1024;                              // Я задаю размер массива\n",
        "    size_t bytes = N * sizeof(float);          // Я считаю байты\n",
        "\n",
        "    float* h = new float[N];                   // Я создаю массив на CPU\n",
        "    for (int i = 0; i < N; i++) h[i] = 1.0f;   // Я заполняю единицами\n",
        "\n",
        "    float *d_in = nullptr, *d_block = nullptr; // Я объявляю указатели GPU\n",
        "    CHECK(cudaMalloc(&d_in, bytes));           // Я выделяю память под вход\n",
        "    CHECK(cudaMemcpy(d_in, h, bytes, cudaMemcpyHostToDevice)); // Я копирую вход на GPU\n",
        "\n",
        "    int threads = 256;                         // Я задаю потоки в блоке\n",
        "    int blocks  = (N + threads - 1) / threads; // Я считаю блоки\n",
        "\n",
        "    CHECK(cudaMalloc(&d_block, blocks * sizeof(float))); // Я выделяю память под суммы блоков\n",
        "\n",
        "    reduceSum<<<blocks, threads>>>(d_in, d_block, N);     // Я запускаю ядро\n",
        "    CHECK(cudaGetLastError());                            // Я проверяю ошибку запуска\n",
        "    CHECK(cudaDeviceSynchronize());                       // Я жду завершения ядра\n",
        "\n",
        "    float* h_block = new float[blocks];                   // Я создаю массив под частичные суммы\n",
        "    CHECK(cudaMemcpy(h_block, d_block, blocks * sizeof(float), cudaMemcpyDeviceToHost)); // Я копирую суммы блоков\n",
        "\n",
        "    float sum = 0.0f;                                     // Я считаю финальную сумму на CPU\n",
        "    for (int i = 0; i < blocks; i++) sum += h_block[i];\n",
        "\n",
        "    cout << \"Reduction result: \" << sum << endl;          // Я вывожу результат (должно быть 1024)\n",
        "\n",
        "    CHECK(cudaFree(d_in));                                // Я освобождаю GPU память\n",
        "    CHECK(cudaFree(d_block));\n",
        "    delete[] h;                                           // Я очищаю CPU память\n",
        "    delete[] h_block;\n",
        "\n",
        "    return 0;                                             // Я завершаю программу\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction -gencode arch=compute_75,code=sm_75\n",
        "!./reduction\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nivIEsn5Nbnv",
        "outputId": "17e3ca6c-cd53-4129-9529-0388744e99a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduction result: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scan.cu\n",
        "#include <iostream>                 // Я подключаю вывод\n",
        "#include <cuda_runtime.h>           // Я подключаю CUDA runtime\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define CHECK(call) do {                                                \\\n",
        "    cudaError_t e = (call);                                             \\\n",
        "    if (e != cudaSuccess) {                                             \\\n",
        "        cerr << \"CUDA error: \" << cudaGetErrorString(e)                 \\\n",
        "             << \" at line \" << __LINE__ << endl;                        \\\n",
        "        return 1;                                                       \\\n",
        "    }                                                                   \\\n",
        "} while(0)\n",
        "\n",
        "__global__ void blellochExclusiveScan(const float* input, float* output, int n) {\n",
        "    __shared__ float temp[256];                 // Я выделяю shared memory на 256 элементов\n",
        "\n",
        "    int tid = threadIdx.x;                      // Я получаю индекс потока\n",
        "    int i = tid;                                // Я работаю с одним блоком (0..255)\n",
        "\n",
        "    temp[tid] = (i < n) ? input[i] : 0.0f;      // Я загружаю вход в shared memory\n",
        "    __syncthreads();                             // Я синхронизирую потоки\n",
        "\n",
        "    // -------- UPSWEEP (строю суммы по дереву) --------\n",
        "    for (int offset = 1; offset < 256; offset <<= 1) {  // Я увеличиваю шаг: 1,2,4,8...\n",
        "        int idx = (tid + 1) * offset * 2 - 1;           // Я считаю индекс узла дерева\n",
        "        if (idx < 256) {                                 // Я проверяю границу\n",
        "            temp[idx] += temp[idx - offset];             // Я складываю левую и правую часть\n",
        "        }\n",
        "        __syncthreads();                                 // Я синхронизирую после шага\n",
        "    }\n",
        "\n",
        "    // Я обнуляю последний элемент для exclusive scan\n",
        "    if (tid == 0) temp[255] = 0.0f;                     // Я делаю старт для обратного прохода\n",
        "    __syncthreads();                                     // Я синхронизирую потоки\n",
        "\n",
        "    // -------- DOWNSWEEP (распределяю префиксы) --------\n",
        "    for (int offset = 128; offset > 0; offset >>= 1) {  // Я уменьшаю шаг: 128,64,32...\n",
        "        int idx = (tid + 1) * offset * 2 - 1;           // Я считаю индекс узла\n",
        "        if (idx < 256) {                                 // Я проверяю границу\n",
        "            float t = temp[idx - offset];                // Я сохраняю левое значение\n",
        "            temp[idx - offset] = temp[idx];              // Я сдвигаю префикс влево\n",
        "            temp[idx] += t;                              // Я обновляю правый узел\n",
        "        }\n",
        "        __syncthreads();                                 // Я синхронизирую после шага\n",
        "    }\n",
        "\n",
        "    if (i < n) output[i] = temp[tid];                    // Я записываю результат exclusive scan\n",
        "}\n",
        "\n",
        "__global__ void makeInclusive(const float* input, float* scanExclusive, float* scanInclusive, int n) {\n",
        "    int i = threadIdx.x;                                 // Я беру индекс элемента (0..255)\n",
        "    if (i < n) scanInclusive[i] = scanExclusive[i] + input[i]; // Я превращаю exclusive в inclusive\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 256;                                   // Я беру размер 256 (1 блок, стабильный вариант)\n",
        "    size_t bytes = N * sizeof(float);                     // Я считаю размер памяти\n",
        "\n",
        "    float* h_in = new float[N];                           // Я создаю входной массив на CPU\n",
        "    for (int i = 0; i < N; i++) h_in[i] = 1.0f;           // Я заполняю его единицами\n",
        "\n",
        "    float *d_in, *d_ex, *d_out;                           // Я объявляю указатели на GPU\n",
        "    CHECK(cudaMalloc(&d_in, bytes));                      // Я выделяю память под вход\n",
        "    CHECK(cudaMalloc(&d_ex, bytes));                      // Я выделяю память под exclusive scan\n",
        "    CHECK(cudaMalloc(&d_out, bytes));                     // Я выделяю память под итоговый inclusive scan\n",
        "\n",
        "    CHECK(cudaMemcpy(d_in, h_in, bytes, cudaMemcpyHostToDevice)); // Я копирую вход на GPU\n",
        "\n",
        "    blellochExclusiveScan<<<1, 256>>>(d_in, d_ex, N);     // Я запускаю Blelloch exclusive scan\n",
        "    CHECK(cudaGetLastError());                            // Я проверяю ошибку запуска\n",
        "    CHECK(cudaDeviceSynchronize());                       // Я жду завершения\n",
        "\n",
        "    makeInclusive<<<1, 256>>>(d_in, d_ex, d_out, N);      // Я делаю inclusive scan\n",
        "    CHECK(cudaGetLastError());                            // Я проверяю ошибку запуска\n",
        "    CHECK(cudaDeviceSynchronize());                       // Я жду завершения\n",
        "\n",
        "    float* h_out = new float[N];                          // Я создаю массив под результат на CPU\n",
        "    CHECK(cudaMemcpy(h_out, d_out, bytes, cudaMemcpyDeviceToHost)); // Я копирую результат\n",
        "\n",
        "    cout << \"Scan result (first 10): \";                   // Я вывожу первые 10 значений\n",
        "    for (int i = 0; i < 10; i++) cout << h_out[i] << \" \";\n",
        "    cout << endl;\n",
        "\n",
        "    CHECK(cudaFree(d_in));                                // Я освобождаю GPU память\n",
        "    CHECK(cudaFree(d_ex));\n",
        "    CHECK(cudaFree(d_out));\n",
        "    delete[] h_in;                                        // Я освобождаю CPU память\n",
        "    delete[] h_out;\n",
        "\n",
        "    return 0;                                             // Я завершаю программу\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dty5DidNefI",
        "outputId": "14e318fb-da87-4cf6-eab9-ff77712c733f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scan.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc scan.cu -o scan -gencode arch=compute_75,code=sm_75\n",
        "!./scan\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1hHi47LNh-R",
        "outputId": "bbb4d5a1-ac65-4f44-c175-8c4edfe8fe74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scan result (first 10): 1 2 3 4 5 6 7 8 9 10 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**\n",
        "\n",
        "В данной практической работе я реализовала два параллельных алгоритма на GPU с использованием CUDA: редукцию (суммирование массива) и сканирование (префиксную сумму). Для ускорения я использовала разделяемую память (shared memory), чтобы уменьшить обращения к глобальной памяти. Корректность я проверила на тестовых данных: редукция дала сумму 1024 для массива из единиц, а сканирование должно выдавать префиксные суммы 1,2,3,… для первых элементов."
      ],
      "metadata": {
        "id": "jgFI6DVPL6Wn"
      }
    }
  ]
}