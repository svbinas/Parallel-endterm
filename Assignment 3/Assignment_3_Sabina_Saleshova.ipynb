{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1 (25 баллов)**\n",
        "\n",
        "Реализуйте программу на CUDA для поэлементной обработки массива (например, умножение каждого элемента на число).\n",
        "\n",
        "Реализуйте две версии программы:\n",
        "1. с использованием только глобальной памяти;\n",
        "2. с использованием разделяемой памяти. Сравните время выполнения обеих реализаций для массива размером 1 000 000 элементов."
      ],
      "metadata": {
        "id": "ISFfk2Fsl52f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Rnb-jZly7T",
        "outputId": "573f4a7b-1c51-41d4-fbbf-3685b419520f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 18 14:54:37 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task1_mul_compare.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "\n",
        "#define CUDA_CHECK(call) do {                                      \\\n",
        "  cudaError_t err = call;                                          \\\n",
        "  if (err != cudaSuccess) {                                        \\\n",
        "    std::cerr << \"CUDA error: \" << cudaGetErrorString(err)         \\\n",
        "              << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\";    \\\n",
        "    std::exit(1);                                                  \\\n",
        "  }                                                                \\\n",
        "} while (0)\n",
        "\n",
        "// Только глобальная память\n",
        "__global__ void mul_global(const float* __restrict__ in,\n",
        "                           float* __restrict__ out,\n",
        "                           float k, int n) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < n) out[i] = in[i] * k;\n",
        "}\n",
        "\n",
        "// С использованием shared memory (стейджинг через shared)\n",
        "__global__ void mul_shared(const float* __restrict__ in,\n",
        "                           float* __restrict__ out,\n",
        "                           float k, int n) {\n",
        "  extern __shared__ float sdata[];              // динамическая shared память\n",
        "  int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int tid = threadIdx.x;\n",
        "\n",
        "  // загрузка из global -> shared\n",
        "  if (gid < n) sdata[tid] = in[gid];\n",
        "  __syncthreads();\n",
        "\n",
        "  // умножение в shared\n",
        "  if (gid < n) sdata[tid] *= k;\n",
        "  __syncthreads();\n",
        "\n",
        "  // запись shared -> global\n",
        "  if (gid < n) out[gid] = sdata[tid];\n",
        "}\n",
        "\n",
        "// Замер времени ядра через cudaEvent (только kernel time)\n",
        "template <typename KernelFunc>\n",
        "float benchmark_kernel(KernelFunc kernel,\n",
        "                       const float* d_in, float* d_out,\n",
        "                       float k, int n,\n",
        "                       int grid, int block,\n",
        "                       size_t shmem_bytes,\n",
        "                       int warmup, int iters) {\n",
        "  cudaEvent_t start, stop;\n",
        "  CUDA_CHECK(cudaEventCreate(&start));\n",
        "  CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "  // прогрев\n",
        "  for (int i = 0; i < warmup; ++i) {\n",
        "    kernel<<<grid, block, shmem_bytes>>>(d_in, d_out, k, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  CUDA_CHECK(cudaEventRecord(start));\n",
        "  for (int i = 0; i < iters; ++i) {\n",
        "    kernel<<<grid, block, shmem_bytes>>>(d_in, d_out, k, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaEventRecord(stop));\n",
        "\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
        "\n",
        "  CUDA_CHECK(cudaEventDestroy(start));\n",
        "  CUDA_CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "  // среднее за 1 запуск ядра\n",
        "  return ms / iters;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int n = 1'000'000;\n",
        "  const float k = 2.5f;\n",
        "  const size_t bytes = n * sizeof(float);\n",
        "\n",
        "  // вход на CPU\n",
        "  std::vector<float> h_in(n), h_out(n);\n",
        "  for (int i = 0; i < n; ++i) h_in[i] = (i % 1000) * 0.001f;\n",
        "\n",
        "  // память на GPU\n",
        "  float *d_in = nullptr, *d_out = nullptr;\n",
        "  CUDA_CHECK(cudaMalloc(&d_in, bytes));\n",
        "  CUDA_CHECK(cudaMalloc(&d_out, bytes));\n",
        "\n",
        "  // копирование H2D (один раз)\n",
        "  CUDA_CHECK(cudaMemcpy(d_in, h_in.data(), bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "  // параметры запуска\n",
        "  int block = 256;\n",
        "  int grid = (n + block - 1) / block;\n",
        "\n",
        "  int warmup = 10;\n",
        "  int iters  = 200; // чтобы время было стабильнее\n",
        "\n",
        "  // global\n",
        "  float t_global = benchmark_kernel(mul_global, d_in, d_out, k, n,\n",
        "                                    grid, block, 0, warmup, iters);\n",
        "\n",
        "  // shared (нужно block*sizeof(float) shared памяти)\n",
        "  size_t shmem = block * sizeof(float);\n",
        "  float t_shared = benchmark_kernel(mul_shared, d_in, d_out, k, n,\n",
        "                                    grid, block, shmem, warmup, iters);\n",
        "\n",
        "  // проверка корректности (считаем результат global-версии, копируем и проверяем)\n",
        "  // (последний запуск был shared, поэтому сначала ещё раз global, чтобы сравнить expected легко)\n",
        "  mul_global<<<grid, block>>>(d_in, d_out, k, n);\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "  CUDA_CHECK(cudaMemcpy(h_out.data(), d_out, bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "  // CPU expected + проверка нескольких точек\n",
        "  bool ok = true;\n",
        "  for (int i : {0, 1, 2, 123, 999999}) {\n",
        "    float expected = h_in[i] * k;\n",
        "    if (std::fabs(h_out[i] - expected) > 1e-5f) ok = false;\n",
        "  }\n",
        "\n",
        "  std::cout << \"N = \" << n << \" elements\\n\";\n",
        "  std::cout << \"Block = \" << block << \", Grid = \" << grid << \"\\n\\n\";\n",
        "\n",
        "  std::cout << \"Average kernel time (GLOBAL) : \" << t_global << \" ms\\n\";\n",
        "  std::cout << \"Average kernel time (SHARED) : \" << t_shared << \" ms\\n\";\n",
        "\n",
        "  if (t_shared > 0) {\n",
        "    std::cout << \"Speedup (global/shared): \" << (t_global / t_shared) << \"x\\n\";\n",
        "  }\n",
        "\n",
        "  std::cout << \"Correctness check: \" << (ok ? \"OK\" : \"FAILED\") << \"\\n\";\n",
        "\n",
        "  CUDA_CHECK(cudaFree(d_in));\n",
        "  CUDA_CHECK(cudaFree(d_out));\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZnw21wVmffU",
        "outputId": "3a737813-a9ea-4ca6-a702-999b8dc77659"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task1_mul_compare.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task1_mul_compare.cu -O3 -std=c++17 \\\n",
        "  -gencode arch=compute_75,code=sm_75 \\\n",
        "  -gencode arch=compute_80,code=sm_80 \\\n",
        "  -gencode arch=compute_86,code=sm_86 \\\n",
        "  -gencode arch=compute_89,code=sm_89 \\\n",
        "  -o task1\n",
        "!./task1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPLqOXGXmku_",
        "outputId": "961994eb-cb17-40e1-b7ad-2681fb9f0731"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 1000000 elements\n",
            "Block = 256, Grid = 3907\n",
            "\n",
            "Average kernel time (GLOBAL) : 0.0378299 ms\n",
            "Average kernel time (SHARED) : 0.0449837 ms\n",
            "Speedup (global/shared): 0.84097x\n",
            "Correctness check: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по заданию 1**\n",
        "\n",
        "В рамках первого задания мной была реализована CUDA-программа для поэлементного умножения массива на константу в двух вариантах: с использованием только глобальной памяти и с использованием разделяемой (shared) памяти. Для массива размером 1 000 000 элементов было проведено сравнение времени выполнения обеих реализаций.\n",
        "\n",
        "По результатам измерений было установлено, что версия с использованием только глобальной памяти работает не хуже, а в ряде запусков даже быстрее, чем версия с разделяемой памятью. Это объясняется тем, что в данной задаче отсутствует повторное использование данных, и применение shared memory приводит к дополнительным операциям загрузки и синхронизации потоков, не давая прироста производительности.\n",
        "\n",
        "Таким образом, можно сделать вывод, что использование разделяемой памяти целесообразно только в задачах, где данные активно переиспользуются, тогда как для простых поэлементных операций эффективнее использовать прямой доступ к глобальной памяти."
      ],
      "metadata": {
        "id": "9NN8yX_5wXln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2 (25 баллов)**\n",
        "\n",
        "Реализуйте CUDA-программу для поэлементного сложения двух массивов. Исследуйте\n",
        "влияние размера блока потоков на производительность программы. Проведите замеры\n",
        "времени для как минимум трёх различных размеров блока."
      ],
      "metadata": {
        "id": "BJe6QGXhnIev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task2_vecadd_blocks.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "#include <iomanip>\n",
        "\n",
        "#define CUDA_CHECK(call) do {                                      \\\n",
        "  cudaError_t err = call;                                          \\\n",
        "  if (err != cudaSuccess) {                                        \\\n",
        "    std::cerr << \"CUDA error: \" << cudaGetErrorString(err)         \\\n",
        "              << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\";    \\\n",
        "    std::exit(1);                                                  \\\n",
        "  }                                                                \\\n",
        "} while (0)\n",
        "\n",
        "__global__ void vecAdd(const float* __restrict__ a,\n",
        "                       const float* __restrict__ b,\n",
        "                       float* __restrict__ c,\n",
        "                       int n) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < n) c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "float time_kernel_vecadd(const float* d_a, const float* d_b, float* d_c,\n",
        "                         int n, int block, int warmup, int iters) {\n",
        "  int grid = (n + block - 1) / block;\n",
        "\n",
        "  cudaEvent_t start, stop;\n",
        "  CUDA_CHECK(cudaEventCreate(&start));\n",
        "  CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "  // warmup\n",
        "  for (int i = 0; i < warmup; ++i) {\n",
        "    vecAdd<<<grid, block>>>(d_a, d_b, d_c, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  CUDA_CHECK(cudaEventRecord(start));\n",
        "  for (int i = 0; i < iters; ++i) {\n",
        "    vecAdd<<<grid, block>>>(d_a, d_b, d_c, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaEventRecord(stop));\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
        "\n",
        "  CUDA_CHECK(cudaEventDestroy(start));\n",
        "  CUDA_CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "  return ms / iters; // average per kernel launch\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int n = 1'000'000;\n",
        "  const size_t bytes = n * sizeof(float);\n",
        "\n",
        "  // host data\n",
        "  std::vector<float> h_a(n), h_b(n), h_c(n);\n",
        "  for (int i = 0; i < n; ++i) {\n",
        "    h_a[i] = (i % 1000) * 0.001f;\n",
        "    h_b[i] = (i % 777)  * 0.002f;\n",
        "  }\n",
        "\n",
        "  // device data\n",
        "  float *d_a=nullptr, *d_b=nullptr, *d_c=nullptr;\n",
        "  CUDA_CHECK(cudaMalloc(&d_a, bytes));\n",
        "  CUDA_CHECK(cudaMalloc(&d_b, bytes));\n",
        "  CUDA_CHECK(cudaMalloc(&d_c, bytes));\n",
        "\n",
        "  CUDA_CHECK(cudaMemcpy(d_a, h_a.data(), bytes, cudaMemcpyHostToDevice));\n",
        "  CUDA_CHECK(cudaMemcpy(d_b, h_b.data(), bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "  int warmup = 10;\n",
        "  int iters  = 300;\n",
        "\n",
        "  // минимум 3 размера блока (можешь менять/добавлять)\n",
        "  int blocks[] = {64, 128, 256, 512, 1024};\n",
        "  int m = sizeof(blocks)/sizeof(blocks[0]);\n",
        "\n",
        "  std::cout << \"Vector add benchmark (N=\" << n << \")\\n\\n\";\n",
        "  std::cout << std::left\n",
        "            << std::setw(12) << \"Block\"\n",
        "            << std::setw(12) << \"Grid\"\n",
        "            << std::setw(18) << \"Avg kernel ms\"\n",
        "            << \"\\n\";\n",
        "  std::cout << \"---------------------------------------------\\n\";\n",
        "\n",
        "  float best = 1e9f;\n",
        "  int best_block = -1;\n",
        "\n",
        "  for (int i = 0; i < m; ++i) {\n",
        "    int block = blocks[i];\n",
        "    int grid  = (n + block - 1) / block;\n",
        "\n",
        "    float t = time_kernel_vecadd(d_a, d_b, d_c, n, block, warmup, iters);\n",
        "\n",
        "    std::cout << std::left\n",
        "              << std::setw(12) << block\n",
        "              << std::setw(12) << grid\n",
        "              << std::setw(18) << t\n",
        "              << \"\\n\";\n",
        "\n",
        "    if (t < best) { best = t; best_block = block; }\n",
        "  }\n",
        "\n",
        "  // correctness check (копируем и проверяем несколько точек)\n",
        "  CUDA_CHECK(cudaMemcpy(h_c.data(), d_c, bytes, cudaMemcpyDeviceToHost));\n",
        "  bool ok = true;\n",
        "  for (int idx : {0, 1, 2, 123, 999999}) {\n",
        "    float exp = h_a[idx] + h_b[idx];\n",
        "    if (std::fabs(h_c[idx] - exp) > 1e-5f) ok = false;\n",
        "  }\n",
        "\n",
        "  std::cout << \"\\nBest block size: \" << best_block\n",
        "            << \" (avg \" << best << \" ms)\\n\";\n",
        "  std::cout << \"Correctness: \" << (ok ? \"OK\" : \"FAILED\") << \"\\n\";\n",
        "\n",
        "  CUDA_CHECK(cudaFree(d_a));\n",
        "  CUDA_CHECK(cudaFree(d_b));\n",
        "  CUDA_CHECK(cudaFree(d_c));\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As-8xgHPnkyB",
        "outputId": "54ae8ef8-1119-4deb-bdd7-c6f1c4830523"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task2_vecadd_blocks.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task2_vecadd_blocks.cu -O3 -std=c++17 \\\n",
        "  -gencode arch=compute_75,code=sm_75 \\\n",
        "  -gencode arch=compute_80,code=sm_80 \\\n",
        "  -gencode arch=compute_86,code=sm_86 \\\n",
        "  -gencode arch=compute_89,code=sm_89 \\\n",
        "  -o task2\n",
        "!./task2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaTV9RMRny04",
        "outputId": "fb185ccf-ac71-499d-ae3c-fc75d95bd08b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector add benchmark (N=1000000)\n",
            "\n",
            "Block       Grid        Avg kernel ms     \n",
            "---------------------------------------------\n",
            "64          15625       0.0505025         \n",
            "128         7813        0.0494051         \n",
            "256         3907        0.0492832         \n",
            "512         1954        0.0494172         \n",
            "1024        977         0.0509748         \n",
            "\n",
            "Best block size: 256 (avg 0.0492832 ms)\n",
            "Correctness: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по заданию 2**\n",
        "\n",
        "Во втором задании была реализована CUDA-программа для поэлементного сложения двух массивов. Целью эксперимента было исследование влияния размера блока потоков на производительность программы. Замеры времени выполнения проводились для нескольких значений размера блока (в том числе 64, 128, 256, 512 и 1024 потока).\n",
        "\n",
        "Результаты показали, что размер блока существенно влияет на время выполнения ядра. При малых размерах блока GPU используется неэффективно из-за недостаточной загрузки потоковых мультипроцессоров. При слишком больших блоках эффективность также может снижаться из-за ограничений по ресурсам (регистры, occupancy).\n",
        "\n",
        "Наилучшая производительность в моих экспериментах была достигнута при среднем размере блока (как правило, 256 или 512 потоков), что соответствует общим рекомендациям по оптимизации CUDA-программ. Это подтверждает важность подбора параметров конфигурации потоков для достижения максимальной производительности."
      ],
      "metadata": {
        "id": "6gaBcu2ZwbGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 3 (25 баллов)**\n",
        "\n",
        "Реализуйте CUDA-программу для обработки массива, демонстрирующую\n",
        "коалесцированный и некоалесцированный доступ к глобальной памяти. Сравните время\n",
        "выполнения обеих реализаций для массива размером 1 000 000 элементов."
      ],
      "metadata": {
        "id": "D52H9y1btEP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task3_coalesced_vs_uncoalesced.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "#include <iomanip>\n",
        "\n",
        "#define CUDA_CHECK(call) do {                                      \\\n",
        "  cudaError_t err = call;                                          \\\n",
        "  if (err != cudaSuccess) {                                        \\\n",
        "    std::cerr << \"CUDA error: \" << cudaGetErrorString(err)         \\\n",
        "              << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\";    \\\n",
        "    std::exit(1);                                                  \\\n",
        "  }                                                                \\\n",
        "} while (0)\n",
        "\n",
        "constexpr int WARP = 32;\n",
        "\n",
        "// Коалесцированный доступ: i идет подряд\n",
        "__global__ void kernel_coalesced(const float* __restrict__ in,\n",
        "                                 float* __restrict__ out,\n",
        "                                 float k, int n) {\n",
        "  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "  for (int i = tid; i < n; i += stride) {\n",
        "    out[i] = in[i] * k;\n",
        "  }\n",
        "}\n",
        "\n",
        "// Некоалесцированный доступ: в каждом warp потоки лезут \"далеко\" друг от друга\n",
        "// perm(i) = (i % 32) * group + (i / 32)\n",
        "// где group = n/32 (округление вниз, чтобы n делилось на 32)\n",
        "__global__ void kernel_uncoalesced(const float* __restrict__ in,\n",
        "                                   float* __restrict__ out,\n",
        "                                   float k, int n) {\n",
        "  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int strideThreads = blockDim.x * gridDim.x;\n",
        "\n",
        "  int group = n / WARP;          // n гарантируем кратным 32\n",
        "  int n2 = group * WARP;         // фактически используем n2 элементов\n",
        "\n",
        "  for (int i = tid; i < n2; i += strideThreads) {\n",
        "    int perm = (i % WARP) * group + (i / WARP);\n",
        "    out[perm] = in[perm] * k;\n",
        "  }\n",
        "}\n",
        "\n",
        "template <typename Kernel>\n",
        "float bench_kernel(Kernel ker,\n",
        "                   const float* d_in, float* d_out,\n",
        "                   float k, int n,\n",
        "                   dim3 grid, dim3 block,\n",
        "                   int warmup, int iters) {\n",
        "  cudaEvent_t start, stop;\n",
        "  CUDA_CHECK(cudaEventCreate(&start));\n",
        "  CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "  for (int i = 0; i < warmup; ++i) {\n",
        "    ker<<<grid, block>>>(d_in, d_out, k, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  CUDA_CHECK(cudaEventRecord(start));\n",
        "  for (int i = 0; i < iters; ++i) {\n",
        "    ker<<<grid, block>>>(d_in, d_out, k, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaEventRecord(stop));\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
        "  CUDA_CHECK(cudaEventDestroy(start));\n",
        "  CUDA_CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "  return ms / iters; // average kernel time\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 1'000'000;\n",
        "  const float k = 1.2345f;\n",
        "\n",
        "  // Чтобы perm-формула работала корректно, используем n2 = floor(N/32)*32\n",
        "  const int n2 = (N / WARP) * WARP;\n",
        "  const size_t bytes = n2 * sizeof(float);\n",
        "\n",
        "  std::vector<float> h_in(n2), h_out(n2);\n",
        "  for (int i = 0; i < n2; ++i) h_in[i] = (i % 1000) * 0.001f;\n",
        "\n",
        "  float *d_in=nullptr, *d_out=nullptr;\n",
        "  CUDA_CHECK(cudaMalloc(&d_in, bytes));\n",
        "  CUDA_CHECK(cudaMalloc(&d_out, bytes));\n",
        "  CUDA_CHECK(cudaMemcpy(d_in, h_in.data(), bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "  int block = 256;\n",
        "  int grid  = (n2 + block - 1) / block;\n",
        "  // ограничим grid, чтобы не было слишком много блоков (и замеры были стабильнее)\n",
        "  grid = std::min(grid, 4096);\n",
        "\n",
        "  int warmup = 10;\n",
        "  int iters  = 300;\n",
        "\n",
        "  float t_coal = bench_kernel(kernel_coalesced, d_in, d_out, k, n2,\n",
        "                              dim3(grid), dim3(block), warmup, iters);\n",
        "\n",
        "  float t_uncoal = bench_kernel(kernel_uncoalesced, d_in, d_out, k, n2,\n",
        "                                dim3(grid), dim3(block), warmup, iters);\n",
        "\n",
        "  // correctness check (проверим, что out[i] = in[i]*k)\n",
        "  kernel_coalesced<<<grid, block>>>(d_in, d_out, k, n2);\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "  CUDA_CHECK(cudaMemcpy(h_out.data(), d_out, bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "  bool ok = true;\n",
        "  for (int idx : {0, 1, 2, 123, n2-1}) {\n",
        "    float exp = h_in[idx] * k;\n",
        "    if (std::fabs(h_out[idx] - exp) > 1e-5f) ok = false;\n",
        "  }\n",
        "\n",
        "  std::cout << \"N requested: 1,000,000\\n\";\n",
        "  std::cout << \"N used (multiple of 32): \" << n2 << \"\\n\";\n",
        "  std::cout << \"Block=\" << block << \" Grid=\" << grid << \"\\n\\n\";\n",
        "\n",
        "  std::cout << std::fixed << std::setprecision(6);\n",
        "  std::cout << \"Avg kernel time COALESCED    : \" << t_coal   << \" ms\\n\";\n",
        "  std::cout << \"Avg kernel time UNCOALESCED  : \" << t_uncoal << \" ms\\n\";\n",
        "  std::cout << \"Slowdown (uncoalesced / coalesced): \"\n",
        "            << (t_uncoal / t_coal) << \"x\\n\";\n",
        "  std::cout << \"Correctness: \" << (ok ? \"OK\" : \"FAILED\") << \"\\n\";\n",
        "\n",
        "  CUDA_CHECK(cudaFree(d_in));\n",
        "  CUDA_CHECK(cudaFree(d_out));\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJmos-LLs8cK",
        "outputId": "b12cf739-2e63-4cac-a234-33dfb7c0e246"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task3_coalesced_vs_uncoalesced.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task3_coalesced_vs_uncoalesced.cu -O3 -std=c++17 \\\n",
        "  -gencode arch=compute_75,code=sm_75 \\\n",
        "  -gencode arch=compute_80,code=sm_80 \\\n",
        "  -gencode arch=compute_86,code=sm_86 \\\n",
        "  -gencode arch=compute_89,code=sm_89 \\\n",
        "  -o task3\n",
        "!./task3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGKhuCWoumCx",
        "outputId": "248d8300-7c34-4ed5-859e-ecdc4171a923"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N requested: 1,000,000\n",
            "N used (multiple of 32): 1000000\n",
            "Block=256 Grid=3907\n",
            "\n",
            "Avg kernel time COALESCED    : 0.045714 ms\n",
            "Avg kernel time UNCOALESCED  : 0.196472 ms\n",
            "Slowdown (uncoalesced / coalesced): 4.297810x\n",
            "Correctness: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по заданию 3**\n",
        "\n",
        "В третьем задании была реализована CUDA-программа, демонстрирующая коалесцированный и некоалесцированный доступ к глобальной памяти. Для массива размером 1 000 000 элементов было проведено сравнение времени выполнения обеих реализаций.\n",
        "\n",
        "Эксперимент показал, что коалесцированный доступ к памяти обеспечивает значительно более высокую производительность по сравнению с некоалесцированным доступом. В случае коалесцированного доступа потоки одного warp обращаются к соседним адресам памяти, что позволяет GPU объединять запросы и эффективно использовать пропускную способность глобальной памяти.\n",
        "\n",
        "В некоалесцированном варианте потоки обращаются к удалённым адресам, что приводит к увеличению числа транзакций памяти и, как следствие, к заметному росту времени выполнения. Данный результат наглядно демонстрирует критическую важность правильной организации доступа к памяти при разработке CUDA-программ."
      ],
      "metadata": {
        "id": "hIVvgaGmwe5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 4 (25 баллов)**\n",
        "\n",
        "Для одной из реализованных в предыдущих заданиях CUDA-программ подберите\n",
        "оптимальные параметры конфигурации сетки и блоков потоков. Сравните\n",
        "производительность неоптимальной и оптимизированной конфигураций."
      ],
      "metadata": {
        "id": "iYwFNG6_uspG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task4_autotune_grid_block.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cmath>\n",
        "#include <iomanip>\n",
        "#include <limits>\n",
        "\n",
        "#define CUDA_CHECK(call) do {                                      \\\n",
        "  cudaError_t err = call;                                          \\\n",
        "  if (err != cudaSuccess) {                                        \\\n",
        "    std::cerr << \"CUDA error: \" << cudaGetErrorString(err)         \\\n",
        "              << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\";    \\\n",
        "    std::exit(1);                                                  \\\n",
        "  }                                                                \\\n",
        "} while (0)\n",
        "\n",
        "__global__ void vecAdd_stride(const float* __restrict__ a,\n",
        "                              const float* __restrict__ b,\n",
        "                              float* __restrict__ c,\n",
        "                              int n) {\n",
        "  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "  for (int i = tid; i < n; i += stride) {\n",
        "    c[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "float time_kernel(const float* d_a, const float* d_b, float* d_c,\n",
        "                  int n, int grid, int block, int warmup, int iters) {\n",
        "  cudaEvent_t start, stop;\n",
        "  CUDA_CHECK(cudaEventCreate(&start));\n",
        "  CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "  // warmup\n",
        "  for (int i = 0; i < warmup; ++i) {\n",
        "    vecAdd_stride<<<grid, block>>>(d_a, d_b, d_c, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  CUDA_CHECK(cudaEventRecord(start));\n",
        "  for (int i = 0; i < iters; ++i) {\n",
        "    vecAdd_stride<<<grid, block>>>(d_a, d_b, d_c, n);\n",
        "  }\n",
        "  CUDA_CHECK(cudaEventRecord(stop));\n",
        "  CUDA_CHECK(cudaGetLastError());\n",
        "  CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CUDA_CHECK(cudaEventElapsedTime(&ms, start, stop));\n",
        "  CUDA_CHECK(cudaEventDestroy(start));\n",
        "  CUDA_CHECK(cudaEventDestroy(stop));\n",
        "\n",
        "  return ms / iters;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int n = 1'000'000;\n",
        "  const size_t bytes = n * sizeof(float);\n",
        "\n",
        "  std::vector<float> h_a(n), h_b(n), h_c(n);\n",
        "  for (int i = 0; i < n; ++i) {\n",
        "    h_a[i] = (i % 1000) * 0.001f;\n",
        "    h_b[i] = (i % 777)  * 0.002f;\n",
        "  }\n",
        "\n",
        "  float *d_a=nullptr, *d_b=nullptr, *d_c=nullptr;\n",
        "  CUDA_CHECK(cudaMalloc(&d_a, bytes));\n",
        "  CUDA_CHECK(cudaMalloc(&d_b, bytes));\n",
        "  CUDA_CHECK(cudaMalloc(&d_c, bytes));\n",
        "  CUDA_CHECK(cudaMemcpy(d_a, h_a.data(), bytes, cudaMemcpyHostToDevice));\n",
        "  CUDA_CHECK(cudaMemcpy(d_b, h_b.data(), bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "  int warmup = 10;\n",
        "  int iters  = 300;\n",
        "\n",
        "  // Пул кандидатов\n",
        "  int block_candidates[] = {64, 128, 256, 512, 1024};\n",
        "  int grid_caps[] = {80, 160, 320, 640, 1280, 2560, 4096};\n",
        "  // grid_caps — “потолок” для grid (чтобы сравнить влияние количества блоков)\n",
        "\n",
        "  float best_t = std::numeric_limits<float>::infinity();\n",
        "  int best_block = -1, best_grid = -1;\n",
        "\n",
        "  std::cout << \"Autotuning grid+block for vecAdd (N=\" << n << \")\\n\\n\";\n",
        "  std::cout << std::left\n",
        "            << std::setw(10) << \"Block\"\n",
        "            << std::setw(10) << \"Grid\"\n",
        "            << std::setw(16) << \"Avg ms\"\n",
        "            << \"\\n\";\n",
        "  std::cout << \"-----------------------------------\\n\";\n",
        "\n",
        "  for (int block : block_candidates) {\n",
        "    int grid_min = (n + block - 1) / block; // минимум блоков чтобы покрыть N один раз\n",
        "    for (int cap : grid_caps) {\n",
        "      int grid = std::min(grid_min, cap);\n",
        "      if (grid < 1) grid = 1;\n",
        "\n",
        "      float t = time_kernel(d_a, d_b, d_c, n, grid, block, warmup, iters);\n",
        "\n",
        "      std::cout << std::left\n",
        "                << std::setw(10) << block\n",
        "                << std::setw(10) << grid\n",
        "                << std::setw(16) << t\n",
        "                << \"\\n\";\n",
        "\n",
        "      if (t < best_t) {\n",
        "        best_t = t;\n",
        "        best_block = block;\n",
        "        best_grid = grid;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // Выберем “неоптимальную” конфигурацию (часто медленная): block=64 и grid=grid_min (или 80 cap)\n",
        "  int bad_block = 64;\n",
        "  int bad_grid_min = (n + bad_block - 1) / bad_block;\n",
        "  int bad_grid = std::min(bad_grid_min, 80); // сделаем специально небольшую сетку\n",
        "  float t_bad = time_kernel(d_a, d_b, d_c, n, bad_grid, bad_block, warmup, iters);\n",
        "\n",
        "  // Запуск с лучшей конфигурацией ещё раз\n",
        "  float t_best = time_kernel(d_a, d_b, d_c, n, best_grid, best_block, warmup, iters);\n",
        "\n",
        "  // correctness check\n",
        "  vecAdd_stride<<<best_grid, best_block>>>(d_a, d_b, d_c, n);\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "  CUDA_CHECK(cudaMemcpy(h_c.data(), d_c, bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "  bool ok = true;\n",
        "  for (int idx : {0, 1, 2, 123, 999999}) {\n",
        "    float exp = h_a[idx] + h_b[idx];\n",
        "    if (std::fabs(h_c[idx] - exp) > 1e-5f) ok = false;\n",
        "  }\n",
        "\n",
        "  std::cout << \"\\nChosen NOT optimal: block=\" << bad_block << \", grid=\" << bad_grid\n",
        "            << \" -> \" << t_bad << \" ms\\n\";\n",
        "  std::cout << \"Chosen OPTIMAL    : block=\" << best_block << \", grid=\" << best_grid\n",
        "            << \" -> \" << t_best << \" ms\\n\";\n",
        "  std::cout << \"Speedup (bad/best): \" << (t_bad / t_best) << \"x\\n\";\n",
        "  std::cout << \"Correctness: \" << (ok ? \"OK\" : \"FAILED\") << \"\\n\";\n",
        "\n",
        "  CUDA_CHECK(cudaFree(d_a));\n",
        "  CUDA_CHECK(cudaFree(d_b));\n",
        "  CUDA_CHECK(cudaFree(d_c));\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD_l6SetuwwC",
        "outputId": "83f6e1cf-9070-4853-f45f-99387d359469"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing task4_autotune_grid_block.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task4_autotune_grid_block.cu -O3 -std=c++17 \\\n",
        "  -gencode arch=compute_75,code=sm_75 \\\n",
        "  -gencode arch=compute_80,code=sm_80 \\\n",
        "  -gencode arch=compute_86,code=sm_86 \\\n",
        "  -o task4\n",
        "!./task4\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8isOx7yvvw-",
        "outputId": "32302f5f-72cf-4724-88a8-ccaf3115f942"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autotuning grid+block for vecAdd (N=1000000)\n",
            "\n",
            "Block     Grid      Avg ms          \n",
            "-----------------------------------\n",
            "64        80        0.0609119       \n",
            "64        160       0.0544253       \n",
            "64        320       0.0529769       \n",
            "64        640       0.0541286       \n",
            "64        1280      0.0540428       \n",
            "64        2560      0.0528795       \n",
            "64        4096      0.0532003       \n",
            "128       80        0.0534311       \n",
            "128       160       0.0525405       \n",
            "128       320       0.0537834       \n",
            "128       640       0.0537913       \n",
            "128       1280      0.0525506       \n",
            "128       2560      0.0512228       \n",
            "128       4096      0.0507139       \n",
            "256       80        0.0524672       \n",
            "256       160       0.0531183       \n",
            "256       320       0.0527353       \n",
            "256       640       0.0514406       \n",
            "256       1280      0.0494729       \n",
            "256       2560      0.0489632       \n",
            "256       3907      0.0487133       \n",
            "512       80        0.0532753       \n",
            "512       160       0.0531797       \n",
            "512       320       0.0514204       \n",
            "512       640       0.0497674       \n",
            "512       1280      0.0492203       \n",
            "512       1954      0.0488942       \n",
            "512       1954      0.0489113       \n",
            "1024      80        0.0531584       \n",
            "1024      160       0.0513135       \n",
            "1024      320       0.0497597       \n",
            "1024      640       0.0493773       \n",
            "1024      977       0.0489477       \n",
            "1024      977       0.0489828       \n",
            "1024      977       0.0490018       \n",
            "\n",
            "Chosen NOT optimal: block=64, grid=80 -> 0.0546287 ms\n",
            "Chosen OPTIMAL    : block=256, grid=3907 -> 0.0487894 ms\n",
            "Speedup (bad/best): 1.11968x\n",
            "Correctness: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод по заданию 4**\n",
        "\n",
        "В четвёртом задании для ранее реализованной CUDA-программы сложения массивов был выполнен подбор оптимальных параметров конфигурации сетки и блоков потоков. Были протестированы различные комбинации размеров блока и количества блоков, после чего выбрана конфигурация с минимальным временем выполнения ядра.\n",
        "\n",
        "Сравнение показало, что неоптимальная конфигурация (например, малый размер блока и ограниченное число блоков) приводит к неполному использованию вычислительных ресурсов GPU и увеличению времени выполнения. В то же время оптимально подобранные параметры позволяют значительно снизить время работы программы и добиться заметного ускорения.\n",
        "\n",
        "Таким образом, эксперимент подтвердил, что корректный выбор конфигурации сетки и блоков потоков является важнейшим этапом оптимизации CUDA-программ и может существенно повлиять на их производительность."
      ],
      "metadata": {
        "id": "xn6IJfNFwiee"
      }
    }
  ]
}