# Assignment 3 — Архитектура GPU и оптимизация CUDA-программ

## Задания

### 1. Поэлементное умножение массива (1 000 000 чисел)
- Реализация CUDA-программы для поэлементного умножения массива
- Две версии программы:
  - с использованием только глобальной памяти
  - с использованием разделяемой (shared) памяти
- Замер времени выполнения обеих версий
- Сравнение производительности global и shared memory

### 2. Поэлементное сложение двух массивов (CUDA)
- Размер массивов: 1 000 000 элементов
- Реализация CUDA-ядра для сложения массивов
- Изменение размера блока потоков (64, 128, 256, 512 и др.)
- Замер времени выполнения для разных размеров блока
- Сравнение полученных результатов

### 3. Коалесцированный и некоалесцированный доступ к памяти
- Реализация CUDA-ядра с коалесцированным доступом к глобальной памяти
- Реализация CUDA-ядра с некоалесцированным доступом
- Размер массива: 1 000 000 элементов
- Сравнение времени выполнения обеих реализаций
- Анализ влияния шаблона доступа к памяти на производительность

### 4. Подбор оптимальной конфигурации сетки и блоков потоков
- Выбор одной из ранее реализованных CUDA-программ
- Перебор различных размеров блока и сетки
- Определение оптимальной конфигурации
- Сравнение неоптимальной и оптимизированной конфигураций
- Подсчёт ускорения

## Контрольные вопросы

### 1. Типы памяти в CUDA
- Регистры — самая быстрая память, доступная одному потоку
- Разделяемая память — быстрая память для потоков одного блока
- Глобальная память — большая по объёму, но с высокой задержкой доступа
- Константная и текстурная память — специализированные типы памяти

### 2. Использование разделяемой памяти
- Эффективна при повторном использовании данных
- Применяется в тильных алгоритмах (матричное умножение, свёртки)

### 3. Шаблон доступа к памяти
- Коалесцированный доступ повышает производительность
- Некоалесцированный доступ увеличивает число транзакций памяти

### 4. Разное время выполнения одного алгоритма
- Зависит от способа обращения к памяти
- Влияет количество транзакций и задержек доступа

### 5. Размер блока потоков
- Влияет на загрузку GPU
- Определяет эффективность выполнения ядра

### 6. Варп
- Группа из 32 потоков
- Важно учитывать при разработке CUDA-программ

### 7. Конфигурация сетки и блоков
- Размер данных
- Архитектура GPU
- Использование регистров и разделяемой памяти

### 8. Оптимизация с памяти
- Доступ к памяти — основное узкое место GPU
- Оптимизация памяти часто эффективнее изменения алгоритма
