Assignment 3 — Архитектура GPU и оптимизация CUDA-программ
Задания

Поэлементное умножение массива (1 000 000 чисел)

Реализация CUDA-программы

Две версии:

с использованием только глобальной памяти

с использованием разделяемой (shared) памяти

Замер времени выполнения обеих версий

Сравнение производительности global и shared memory

Поэлементное сложение двух массивов (CUDA)

Размер массивов: 1 000 000 элементов

Реализация CUDA-ядра для сложения

Изменение размера блока потоков (64, 128, 256, …)

Замер времени выполнения для разных размеров блока

Сравнение полученных результатов

Коалесцированный и некоалесцированный доступ к памяти

Реализация CUDA-ядра с коалесцированным доступом к глобальной памяти

Реализация CUDA-ядра с некоалесцированным доступом

Размер массива: 1 000 000 элементов

Сравнение времени выполнения обеих реализаций

Анализ влияния шаблона доступа к памяти на производительность

Подбор оптимальной конфигурации сетки и блоков потоков

Выбор одной из реализованных ранее CUDA-программ

Перебор различных значений:

размера блока потоков

количества блоков сетки

Определение оптимальной конфигурации

Сравнение неоптимальной и оптимизированной конфигураций

Подсчёт ускорения

Контрольные вопросы

Типы памяти в CUDA:

Регистры — самая быстрая память, доступна одному потоку

Разделяемая (shared) память — быстрая память для потоков одного блока

Глобальная память — большая, но с высокой задержкой доступа

Константная и текстурная память — специализированные типы памяти

Когда эффективно использовать разделяемую память:

При повторном использовании данных

В тильных алгоритмах (матричное умножение, свёртки)

Влияние доступа к глобальной памяти:

Коалесцированный доступ повышает производительность

Некоалесцированный доступ увеличивает число транзакций памяти

Почему одинаковый алгоритм может работать по-разному:

Из-за различий в шаблонах доступа к памяти

Из-за разного числа обращений к глобальной памяти

Влияние размера блока потоков:

Малый блок — недостаточная загрузка GPU

Слишком большой блок — ограничения по ресурсам

Оптимальный размер блока обеспечивает баланс производительности

Варп:

Группа из 32 потоков, выполняющихся синхронно

Важно учитывать для предотвращения дивергенции и снижения производительности

Выбор конфигурации сетки и блоков:

Размер данных

Архитектура GPU

Использование регистров и разделяемой памяти

Эффективная загрузка потоковых мультипроцессоров

Почему оптимизация начинается с памяти:

Доступ к памяти является основным узким местом GPU

Оптимизация памяти часто даёт больший прирост, чем изменение алгоритма
