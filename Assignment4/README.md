# Assignment 4 — Гибридные и распределённые параллельные вычисления

## Задания

### 1. Суммирование элементов массива (CPU vs GPU)
- Реализация последовательной программы на CPU для вычисления суммы элементов массива
- Реализация CUDA-программы для вычисления суммы массива с использованием глобальной памяти
- Размер массива: 100 000 элементов
- Замер времени выполнения CPU- и GPU-реализаций
- Сравнение результатов и времени выполнения

### 2. Префиксная сумма (Scan) с использованием разделяемой памяти
- Реализация CUDA-программы для вычисления префиксной суммы массива
- Использование разделяемой (shared) памяти
- Размер массива: 1 000 000 элементов
- Последовательная реализация префиксной суммы на CPU
- Замер времени выполнения CPU- и GPU-версий
- Анализ производительности и особенностей параллельного scan

### 3. Гибридная обработка массива (CPU + GPU)
- Реализация гибридной программы с одновременным использованием CPU и GPU
- Разделение массива на две части:
  - первая часть обрабатывается на CPU
  - вторая часть обрабатывается на GPU
- Размер массива: 1 000 000 элементов
- Реализация CPU-only, GPU-only и Hybrid версий
- Замер и сравнение времени выполнения всех трёх подходов
- Проверка корректности результатов

### 4. Распределённая обработка массива с использованием MPI
- Реализация распределённой программы с использованием MPI
- Разделение массива между процессами с помощью `MPI_Scatter`
- Локальная обработка данных в каждом процессе
- Сбор результатов на главный процесс с помощью `MPI_Gather`
- Размер массива: 1 000 000 элементов
- Замеры времени выполнения для 2, 4 и 8 MPI-процессов
- Анализ влияния числа процессов на производительность

---

## Контрольные вопросы

### 1. Отличие гибридных вычислений от CPU- и GPU-вычислений
- Гибридные вычисления используют одновременно CPU и GPU
- Позволяют эффективнее распределять нагрузку
- Объединяют преимущества последовательных и параллельных вычислений

### 2. Задачи для гибридного подхода
- Обработка больших массивов данных
- Численные и научные вычисления
- Задачи, которые можно разделить на независимые части

### 3. Синхронная и асинхронная передача данных
- Синхронная передача блокирует выполнение программы
- Асинхронная передача выполняется параллельно с вычислениями

### 4. Преимущества асинхронной передачи
- Перекрытие вычислений и копирования данных
- Снижение времени простоя CPU и GPU
- Повышение общей производительности программы

### 5. Основные функции MPI
- `MPI_Scatter` — распределение данных между процессами
- `MPI_Gather` — сбор результатов
- `MPI_Reduce` — объединение локальных результатов
- `MPI_Barrier` — синхронизация процессов

### 6. Влияние числа MPI-процессов на время выполнения
- Увеличение числа процессов может ускорять вычисления
- При ограниченных ресурсах возможен рост накладных расходов
- Эффективность зависит от среды выполнения

### 7. Ограничения масштабируемости
- Затраты на межпроцессное взаимодействие
- Частые синхронизации
- Неравномерная загрузка процессов
- Ограниченные аппаратные ресурсы

### 8. Когда распределённые вычисления эффективны
- При больших объёмах данных и сложных вычислениях
- При наличии достаточных вычислительных ресурсов
- Неэффективны для малых задач с большими накладными расходами
